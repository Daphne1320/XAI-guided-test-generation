{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4b76a0f-33cc-4a4c-b44c-5a807abaef5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from compare import *\n",
    "#from lava_generator import *\n",
    "from xai import latent_space_display_mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6463d2bc-fca3-4a85-9838-ece90d39efbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb3cb143d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "7/7 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "vae = VAE.load(\"trained_models/VAE\")\n",
    "cnn = load_model(\"trained_models/CNN/classifier.h5\")\n",
    "xai = xai_model(vae.decoder, cnn, input_shape=(10,))\n",
    "\n",
    "# input images\n",
    "# samples_test, sample_labels_test = load_samples_for_test_folder(img_dir='./contrib/DLFuzz/MNIST/seeds_50')\n",
    "samples_test, sample_labels_test = load_samples_for_test(200)\n",
    "\n",
    "# prepare\n",
    "view_samples = samples_test\n",
    "view_sample_labels = sample_labels_test\n",
    "# view_samples = samples\n",
    "# view_sample_labels = sample_labels\n",
    "\n",
    "x_view = np.reshape(view_samples, (-1, 784))\n",
    "y_view_onehot = tf.one_hot(tf.constant(view_sample_labels), depth=10).numpy()\n",
    "h_view = vae.encoder.predict(x_view)\n",
    "\n",
    "K.set_learning_phase(0)\n",
    "dlfuzz = DLFuzz(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e1fdf53-4899-40f8-a7a6-4494c6979393",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_adversarial_with_deep_optimizer(h_view, label, learning_rate=0.01, num_iterations=100):\n",
    "    # load models\n",
    "    vae = VAE.load(\"trained_models/VAE\")\n",
    "    cnn = load_model(\"trained_models/CNN/classifier.h5\")\n",
    "    xai = xai_model(vae.decoder, cnn, input_shape=(10,))\n",
    "\n",
    "    # prepare data\n",
    "    x = np.array([h_view])\n",
    "    y = np.array([label])\n",
    "\n",
    "\n",
    "    # Use Adam optimizer\n",
    "    optimizer = tf.optimizers.Adam(learning_rate)\n",
    "    for iteration in range(num_iterations):\n",
    "        # Compute gradient using the customized method\n",
    "        gradient = gradient_of_x(x, y, xai)\n",
    "        #x_var = tf.Variable(x, dtype=tf.float32)\n",
    "        optimizer.apply_gradients([(gradient, x)])\n",
    "\n",
    "        # Decode the perturbed image and check if misclassified\n",
    "        decoded_image = vae.decoder.predict(x).reshape((28, 28, 1))\n",
    "\n",
    "        # Check if the decoded image is misclassified by the CNN\n",
    "        prediction = cnn.predict(np.array([decoded_image]))[0]\n",
    "        predicted_label = np.argmax(prediction)\n",
    "\n",
    "        if predicted_label != np.argmax(y):\n",
    "            print(f\"Misclassification achieved at iteration {iteration}\")\n",
    "            break\n",
    "\n",
    "    return [decoded_image, predicted_label]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f02976c-e227-4505-9968-78c6251a7186",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute '_unique_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m num_iterations \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m  \u001b[38;5;66;03m# Number of iterations for gradient descent\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Adversarial example generation\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m [decoded_image, prediction] \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_adversarial_with_deep_optimizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh_view\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_view_onehot\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_iterations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m image_gen_lava \u001b[38;5;241m=\u001b[39m vae\u001b[38;5;241m.\u001b[39mdecoder\u001b[38;5;241m.\u001b[39mpredict(x)\n\u001b[1;32m     23\u001b[0m images \u001b[38;5;241m=\u001b[39m [image_org, decoded_image]\n",
      "Cell \u001b[0;32mIn[10], line 18\u001b[0m, in \u001b[0;36mgenerate_adversarial_with_deep_optimizer\u001b[0;34m(h_view, label, learning_rate, num_iterations)\u001b[0m\n\u001b[1;32m     16\u001b[0m gradient \u001b[38;5;241m=\u001b[39m gradient_of_x(x, y, xai)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#x_var = tf.Variable(x, dtype=tf.float32)\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Decode the perturbed image and check if misclassified\u001b[39;00m\n\u001b[1;32m     21\u001b[0m decoded_image \u001b[38;5;241m=\u001b[39m vae\u001b[38;5;241m.\u001b[39mdecoder\u001b[38;5;241m.\u001b[39mpredict(x)\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m/opt/anaconda3/envs/bachelor/lib/python3.9/site-packages/keras/optimizers/optimizer.py:1174\u001b[0m, in \u001b[0;36mOptimizer.apply_gradients\u001b[0;34m(self, grads_and_vars, name, skip_gradients_aggregation, **kwargs)\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skip_gradients_aggregation \u001b[38;5;129;01mand\u001b[39;00m experimental_aggregate_gradients:\n\u001b[1;32m   1173\u001b[0m     grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maggregate_gradients(grads_and_vars)\n\u001b[0;32m-> 1174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads_and_vars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/bachelor/lib/python3.9/site-packages/keras/optimizers/optimizer.py:637\u001b[0m, in \u001b[0;36m_BaseOptimizer.apply_gradients\u001b[0;34m(self, grads_and_vars, name)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mname_scope(scope_name):\n\u001b[1;32m    634\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39minit_scope():\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;66;03m# Lift variable creation to init scope to avoid environment\u001b[39;00m\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;66;03m# issues.\u001b[39;00m\n\u001b[0;32m--> 637\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    638\u001b[0m grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(grads, trainable_variables))\n\u001b[1;32m    639\u001b[0m grads_and_vars \u001b[38;5;241m=\u001b[39m optimizer_utils\u001b[38;5;241m.\u001b[39mfilter_empty_gradients(grads_and_vars)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/bachelor/lib/python3.9/site-packages/keras/optimizers/adam.py:131\u001b[0m, in \u001b[0;36mAdam.build\u001b[0;34m(self, var_list)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild\u001b[39m(\u001b[38;5;28mself\u001b[39m, var_list):\n\u001b[1;32m    123\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Initialize optimizer variables.\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \n\u001b[1;32m    125\u001b[0m \u001b[38;5;124;03m    Adam optimizer has 3 types of variables: momentums, velocities and\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03m      var_list: list of model variables to build Adam variables on.\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 131\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_built\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_built:\n\u001b[1;32m    133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/bachelor/lib/python3.9/site-packages/keras/optimizers/optimizer.py:415\u001b[0m, in \u001b[0;36m_BaseOptimizer.build\u001b[0;34m(self, var_list)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_built\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    414\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 415\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_index_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_ema:\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_variables_moving_average \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/opt/anaconda3/envs/bachelor/lib/python3.9/site-packages/keras/optimizers/optimizer.py:441\u001b[0m, in \u001b[0;36m_BaseOptimizer._build_index_dict\u001b[0;34m(self, var_list)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, var \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(var_list):\n\u001b[0;32m--> 441\u001b[0m     var_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_var_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_dict[var_key] \u001b[38;5;241m=\u001b[39m i\n",
      "File \u001b[0;32m/opt/anaconda3/envs/bachelor/lib/python3.9/site-packages/keras/optimizers/optimizer.py:1125\u001b[0m, in \u001b[0;36mOptimizer._var_key\u001b[0;34m(self, variable)\u001b[0m\n\u001b[1;32m   1117\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[1;32m   1118\u001b[0m     tf_utils\u001b[38;5;241m.\u001b[39mis_extension_type(variable)\n\u001b[1;32m   1119\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(variable, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhandle\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;66;03m# For ResourceVariables, the _distributed_container attribute\u001b[39;00m\n\u001b[1;32m   1123\u001b[0m     \u001b[38;5;66;03m# is added to their handle tensors.\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m     variable \u001b[38;5;241m=\u001b[39m variable\u001b[38;5;241m.\u001b[39mhandle\u001b[38;5;241m.\u001b[39m_distributed_container()\n\u001b[0;32m-> 1125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_var_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariable\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/bachelor/lib/python3.9/site-packages/keras/optimizers/optimizer.py:161\u001b[0m, in \u001b[0;36m_BaseOptimizer._var_key\u001b[0;34m(self, variable)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get a unique identifier of the given variable.\"\"\"\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;66;03m# Get the distributed variable if it exists.\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# TODO(b/199214315): replace _unique_id with ref() after fixing ref()\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;66;03m# issues on AggregatingVariable.\u001b[39;00m\n\u001b[0;32m--> 161\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_unique_id\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute '_unique_id'"
     ]
    }
   ],
   "source": [
    "# calculate latent variant image\n",
    "i = 3\n",
    "\n",
    "image_org = np.array([view_samples[i]], dtype=\"float32\")\n",
    "label_org = view_sample_labels[i]\n",
    "\n",
    "x = np.array([h_view[i]])\n",
    "y = np.array([y_view_onehot[i]])\n",
    "\n",
    "# Compute initial gradient\n",
    "g = gradient_of_x(x, y, xai)\n",
    "\n",
    "g_npy = np.squeeze(g.numpy())\n",
    "\n",
    "# Parameters for gradient descent\n",
    "alpha = 0.01  # Learning rate\n",
    "num_iterations = 10  # Number of iterations for gradient descent\n",
    "\n",
    "# Adversarial example generation\n",
    "[decoded_image, prediction] = generate_adversarial_with_deep_optimizer(h_view[1], y_view_onehot[1], alpha, num_iterations)\n",
    "\n",
    "image_gen_lava = vae.decoder.predict(x)\n",
    "images = [image_org, decoded_image]\n",
    "titles = [f'image_org_{label_org}', f'image_gen_lava_{prediction}']\n",
    "plot_image_comparison(images, titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea65108-d890-412a-ba3d-b9bfde73fb1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b837bc-13bc-49a2-af8e-0724e2b628b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6969485a-d1c3-4464-b0c7-732556bbe4aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5714e269-8292-4ce0-bf04-31bdf92e843c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120377d1-67af-41b5-ae21-eb07cb6a2885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371bce53-d4c6-434e-8607-5260f2ef2702",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1276901f-dd89-4630-8e51-38308db98348",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ce6fb6-9100-48c6-bd56-58110a9bd36d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python bachelor",
   "language": "python",
   "name": "bachelor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
