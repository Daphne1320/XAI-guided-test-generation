{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3184d771",
   "metadata": {},
   "outputs": [],
   "source": [
    "from compare_adversarial import *\n",
    "from xai import latent_space_display_mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7d84bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "7/7 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/bachelor/lib/python3.9/site-packages/keras/backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "vae = VAE.load(\"trained_models/VAE\")\n",
    "cnn = load_model(\"trained_models/CNN/classifier.h5\")\n",
    "xai = xai_model(vae.decoder, cnn, input_shape=(12,))\n",
    "\n",
    "# input images\n",
    "# samples_test, sample_labels_test = load_samples_for_test_folder(img_dir='./contrib/DLFuzz/MNIST/seeds_50')\n",
    "samples_test, sample_labels_test = load_samples_for_test(200)\n",
    "\n",
    "# prepare\n",
    "view_samples = samples_test\n",
    "view_sample_labels = sample_labels_test\n",
    "# view_samples = samples\n",
    "# view_sample_labels = sample_labels\n",
    "\n",
    "x_view = np.reshape(view_samples, (-1, 784))\n",
    "y_view_onehot = tf.one_hot(tf.constant(view_sample_labels), depth=10).numpy()\n",
    "h_view = vae.encoder.predict(x_view)\n",
    "\n",
    "K.set_learning_phase(0)\n",
    "dlfuzz = DLFuzz(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef2feb7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/200 [00:02<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'gradient_of_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([h_view[i]])\n\u001b[1;32m     13\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([y_view_onehot[i]])\n\u001b[0;32m---> 14\u001b[0m g \u001b[38;5;241m=\u001b[39m \u001b[43mgradient_of_x\u001b[49m(x, y, xai)\n\u001b[1;32m     15\u001b[0m g_npy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqueeze(g\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# var = 0.5\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# h_lava = get_h_lava_via_one_step(x, g_npy, step=var)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# image_gen_lava = vae.decoder.predict(h_lava)[0].reshape((28, 28, 1))\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gradient_of_x' is not defined"
     ]
    }
   ],
   "source": [
    "# start\n",
    "for i in tqdm(range(len(x_view))):\n",
    "\n",
    "    # calculate fuzz image\n",
    "    image_org = np.array([view_samples[i]], dtype=\"float32\")\n",
    "    label_org = view_sample_labels[i]\n",
    "    image_gen_fuzz = dlfuzz.generate_adversarial_image(image_org)\n",
    "    print(image_gen_fuzz.shape)\n",
    "    # of shape (28, 28, 1)\n",
    "\n",
    "    # calculate latent variant image\n",
    "    x = np.array([h_view[i]])\n",
    "    y = np.array([y_view_onehot[i]])\n",
    "    g = gradient_of_x(x, y, xai)\n",
    "    g_npy = np.squeeze(g.numpy())\n",
    "    \n",
    "    # var = 0.5\n",
    "    # h_lava = get_h_lava_via_one_step(x, g_npy, step=var)\n",
    "    # image_gen_lava = vae.decoder.predict(h_lava)[0].reshape((28, 28, 1))\n",
    "\n",
    "    alpha = 0.01  # Learning rate\n",
    "    num_iterations = 100  # Number of iterations for gradient descent\n",
    "    [image_gen_lava, prediction] = gradient_descent_generate(h_view[i], y_view_onehot[i], alpha, num_iterations)\n",
    "\n",
    "    label_fuzz = np.argmax(cnn.predict(np.array([image_gen_fuzz]))[0])\n",
    "    label_lava = np.argmax(cnn.predict(np.array([image_gen_lava]))[0])\n",
    "\n",
    "    # List of images and their titles\n",
    "    images = [image_org, image_gen_fuzz, image_gen_lava]\n",
    "    titles = [f'image_org_{label_org}', f'image_gen_fuzz_{label_fuzz}', f'image_gen_lava_{label_lava}']\n",
    "\n",
    "    # Plot the images\n",
    "    if label_lava != label_org:\n",
    "        plot_image_comparison(images, titles)\n",
    "\n",
    "        # in latent space\n",
    "        # Euclidean distance (L2 norm) \n",
    "        h_fuzz = vae.encoder.predict(np.array([image_gen_fuzz.reshape((784,))]))[0]\n",
    "        d_fuzz = np.linalg.norm(x - h_fuzz)\n",
    "        d_lava = np.linalg.norm(x - h_lava)\n",
    "        print(f\"d_fuzz: {d_fuzz}\\nd_lava: {d_lava}\")\n",
    "\n",
    "        # in image space\n",
    "        kl_fuzz = kl_divergence(image_org, image_gen_fuzz)\n",
    "        kl_lava = kl_divergence(image_org, image_gen_lava)\n",
    "        print(f\"kl_fuzz: {kl_fuzz}\\nkl_lava: {kl_lava}\")\n",
    "\n",
    "        ws_fuzz = ws_distance(image_org, image_gen_fuzz)\n",
    "        ws_lava = ws_distance(image_org, image_gen_lava)\n",
    "        print(f\"ws_fuzz: {ws_fuzz}\\nws_lava: {ws_lava}\")\n",
    "\n",
    "        js_fuzz = js_divergence(image_org, image_gen_fuzz)\n",
    "        js_lava = js_divergence(image_org, image_gen_lava)\n",
    "        print(f\"js_fuzz: {js_fuzz}\\njs_lava: {js_lava}\")\n",
    "\n",
    "        ce_fuzz = cross_entropy(image_org, image_gen_fuzz)\n",
    "        ce_lava = cross_entropy(image_org, image_gen_lava)\n",
    "        print(f\"ce_fuzz: {ce_fuzz}\\nce_lava: {ce_lava}\")\n",
    "\n",
    "        mse_fuzz = mse_loss(image_org, image_gen_fuzz)\n",
    "        mse_lava = mse_loss(image_org, image_gen_lava)\n",
    "        print(f\"mse_fuzz: {mse_fuzz}\\nmse_lava: {mse_lava}\")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python bachelor",
   "language": "python",
   "name": "bachelor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
