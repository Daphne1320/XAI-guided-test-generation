{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0211215c-3dcc-4bbb-adf6-32cfb8abb0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from adversarial import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fff33fe-e49a-4cd0-ac3c-84902b01f88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-07 10:48:08.731412: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/bachelor/lib/python3.9/site-packages/keras/backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "vae = VAE.load(\"trained_models/VAE\")\n",
    "cnn = load_model(\"trained_models/CNN/classifier.h5\")\n",
    "xai = xai_model(vae.decoder, cnn, input_shape=(12,))\n",
    "\n",
    "# input images\n",
    "# samples_test, sample_labels_test = load_samples_for_test_folder(img_dir='./contrib/DLFuzz/MNIST/seeds_50')\n",
    "samples_test, sample_labels_test = load_samples_for_test(200)\n",
    "\n",
    "# prepare\n",
    "samples_view = samples_test\n",
    "sample_labels_view = sample_labels_test\n",
    "# samples_view = samples\n",
    "# sample_labels_view = sample_labels\n",
    "\n",
    "x_view = np.reshape(samples_view, (-1, 784))\n",
    "y_onehot_view = tf.one_hot(tf.constant(sample_labels_view), depth=10).numpy()\n",
    "\n",
    "K.set_learning_phase(0)\n",
    "# dlfuzz = DLFuzz(cnn)\n",
    "clhans = CleverHans(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b148b65-7997-476b-b383-4008670c5e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/200 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "UnparsedFlagAccessError",
     "evalue": "Trying to access flag --eps before flags were parsed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnparsedFlagAccessError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m label_org \u001b[38;5;241m=\u001b[39m sample_labels_view[i]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# generate dlfuzz image\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# image_adv = dlfuzz.generate_adversarial_image(image_org)  # of shape (28, 28, 1)\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m image_adv \u001b[38;5;241m=\u001b[39m \u001b[43mclhans\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_adversarial_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_org\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# of shape (28, 28, 1)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m label \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(cnn\u001b[38;5;241m.\u001b[39mpredict(np\u001b[38;5;241m.\u001b[39marray([image_adv]))[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# List of images and their titles\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/BachelorThesis/XAI-guided-test-generation/contrib/Cleverhans/cleverhans.py:25\u001b[0m, in \u001b[0;36mCleverHans.generate_adversarial_image\u001b[0;34m(self, image, method)\u001b[0m\n\u001b[1;32m     23\u001b[0m method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mFAST_GRADIENT \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m method\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mFAST_GRADIENT:\n\u001b[0;32m---> 25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fast_gradient_method(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, [image], \u001b[43mFLAGS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m, np\u001b[38;5;241m.\u001b[39minf)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mPROJ_GRADIENT:\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m projected_gradient_descent(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, [image], FLAGS\u001b[38;5;241m.\u001b[39meps, \u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m40\u001b[39m, np\u001b[38;5;241m.\u001b[39minf)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/bachelor/lib/python3.9/site-packages/absl/flags/_flagvalues.py:498\u001b[0m, in \u001b[0;36mFlagValues.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    496\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fl[name]\u001b[38;5;241m.\u001b[39mvalue\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 498\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m _exceptions\u001b[38;5;241m.\u001b[39mUnparsedFlagAccessError(\n\u001b[1;32m    499\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrying to access flag --\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m before flags were parsed.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m name)\n",
      "\u001b[0;31mUnparsedFlagAccessError\u001b[0m: Trying to access flag --eps before flags were parsed."
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(x_view))):\n",
    "    # get original image\n",
    "    image_org = samples_view[i]\n",
    "    label_org = sample_labels_view[i]\n",
    "\n",
    "    # generate dlfuzz image\n",
    "    # image_adv = dlfuzz.generate_adversarial_image(image_org)  # of shape (28, 28, 1)\n",
    "    image_adv = clhans.generate_adversarial_image(image_org)  # of shape (28, 28, 1)\n",
    "    label = np.argmax(cnn.predict(np.array([image_adv]))[0])\n",
    "\n",
    "    # List of images and their titles\n",
    "    images = [image_org, image_adv]\n",
    "    titles = [f'image_org_{label_org}', f'image_adv_{label}']\n",
    "\n",
    "    # Plot the images\n",
    "    if label != label_org:\n",
    "        plot_image_comparison_two(images, titles)\n",
    "\n",
    "        kl_fuzz = kl_divergence(image_org, image_adv)\n",
    "        print(f\"kl: {kl_fuzz}\")\n",
    "\n",
    "        ws_fuzz = ws_distance(image_org, image_adv)\n",
    "        print(f\"ws: {ws_fuzz}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python bachelor",
   "language": "python",
   "name": "bachelor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
